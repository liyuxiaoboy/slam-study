slam：simulation location and mapping

定位：我们在哪里 建图：周围长什么样

主类：单目、双目、RGB-D
分类：全景相机、Event相机

单目：二维反应三维，最大问题是丢失一个深度数据无法确认比例尺。
     可利用原理：二维图像上近大远小，近快远慢。（视差）
     平移之后才可确认尺度。
     
双目：两个摄像头之间存在基线，两个摄像头自带视差，直接可以算出深度
最大问题是，基线长度直接决定了最大测量长度，切受最小像素点尺度制约，距离有限计算量大

RGB-D
啥数据都给你，拿去用

视觉SLAM框架
 相机数据——>前端（视觉里程计）——>非线性优化（后端）——>建图
        ——>回环检测————————————>
        
        
视觉里程计 visual odometry  相邻图片之间的相机运动 计算机视觉
后端优化   optimization     处理数据的噪声 滤波 非线性优化
回环检测   loop closing     又称闭环检测（Loop Closure Detection）处理漂移（drift）机器人能够识别到过的地方
建图       mapping          3D点云 3D网格

slam本质是：对运动主体和周围环境空间不确定性的估计

数学表达式有两个核心
1.xk=f(xk-1,uk,wk)
2.zij=h(yi,xk,vkj)
